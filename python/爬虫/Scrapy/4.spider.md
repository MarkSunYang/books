Spider是定义如何抓取某个站点的类，包括如何执行爬虫，包括如何执行爬行（即跟随链接）以及如何从其页面中提取结构化数据（即抓取项目）。换句话说，Spiders是您为特定站点（或者在某些情况下，一组站点）爬网和解析页面定义自定义行为的地方。

生命周期：
1. 出事话请求爬取一个URL
第一个执行请求是通过调用 start_requests()（默认情况下）为在请求中作为回调函数的方法中Request指定的URL start_urls和parse方法生成的 方法获得的。
2. 在回调函数中，您解析响应（网页）并返回带有提取的数据，Item对象， Request对象或这些对象的可迭代的dicts。这些请求还将包含一个回调（可能相同），然后由Scrapy下载，然后由指定的回调处理它们的响应。
3. 回调函数中，您通常使用选择器解析页面内容 （但您也可以使用BeautifulSoup，lxml或您喜欢的任何机制）并使用解析的数据生成项目。
4. 最后，从蜘蛛返回的项目通常会持久保存到数据库（在某些项目管道中）或使用Feed导出写入文件。

类scrapy.spiders.Spider
提供了一个默认start_requests()实现，它从start_urlsspider属性发送请求，并parse 为每个结果响应调用spider的方法。

name:一个字符串，用于定义此Spider的名称
allowed_domains:包含允许此爬网爬网的域的字符串的可选列表。
custom_settings:运行此蜘蛛时将从项目范围配置中覆盖的设置字典。必须将其定义为类属性，因为在实例化之前更新了设置。
crawler:from_crawler()初始化类后，此属性由类方法设置，并链接Crawler到此spider实例绑定到的 对象。