虽然很不愿意照着书打字，但是。。。。

1.1计算机的发展概述，你跟我说宾夕法尼亚，耗电，电子管，每秒的运算次数，我也不懂
我只知道 Von Neumann，奥，计算机的五个基本部件：
输入器，运算器，运算器，存储器和控制器

1.2.3 计算机编程语言的发展
1.机器语言  0，1码语言  
2.汇编语言 用一些助记符号代替0，1
3.高级语言：面向问题的程序设计被成为高级语言
比如工业控制、专家系统、数据管理和数据库等，这些语言属于过程化语言，
4.面向对象语言：
5.基于规则的智能化语言

1.3 微型计算机中信息的表示及运算基础
计算机是如何存储信息的，计算机内部的数据是如何表示的？ 哈哈最初的文件管理系统
好像就是为银行开发的。。。计算机是一种电器设备，它只认识电的信号，
如电平的高与低，电路的通与断，晶体管的导通与截至，电子开关的开与关，将这两种状态用0，1表示，
0或1就是二进制数的一位，成为bit，因此在计算机中，任何信息都必须要用0和1数字组合形式表示，
******现在终于知道为啥小时候想着十进制~~
1个二进制成为1个bit
8个二进制成为一个Byte，也称为一个字节
2个字节成为i一个字 Word  16位
两个字成为双字 DWard Double WOrld 32位
4个连续的字成为四字 QWord 
而连续的10个字节成为十字节  它是一个80位的二进制的值

奥，十进制的由来。。。因为我们基本上都是十个指头，我竟然信了
我回答问题的时候居然是  对，不对，什么时候回答出5花8门的答案。。。到时候肯定能把妹子骗到了
ASCII 码  美国标准信息交换码，代表了键盘上的所有符号，

1.3.1 二进制数的表示与运算
二进制数用 0 1表示，一个8位的二进制数 成为一个Byte 比如 
10010011 我们习惯在二进制后面加上字幕 B  binary 
二进制 
1.3.1.1
加法：逢二进1 0+0=1 1+1=10 0+1=1 1+0=1
减法：借1当二 0-0=0 1-0=1 1-1=0 10-1=1
乘法：1与1 乘 为 1 其他为0 0*0=0 0*1=0 1*0=1 1*1=1
1.3.1.2
逻辑运算
逻辑非 NOT  1→0  0→1
逻辑与 AND 0^0=0  0^1=0 1^0=1 1^1=1
逻辑或 OR 找不到符号了~~
逻辑异或 XOR 模2和

 00011010            11000100
+01101101  +         10110100 
=10000111  =00000001 01101000

 10011011
-00110101
=01100110

十进制~~

十六进制数的表示与运算：
1.十六进制数的表示

十六进制有16个记数符号，0-9 A~F，四个二进制数公有16种组合状态，
二进制 十六进制
0       0
~9      9
10      A
~15     F
十六进制的运算
加法：逢16进1 减法 借1当16
1+9=A 2+A=C ~~

带符号二进制数的表示和运算：
正号和负号在计算机中只能用0 和 1表示，0表示+ 1表示-并且放在最高位有效，


原码、反码和补码
因为二进制数如果在有符号的情况下无法参加运算，所以我们要用补码表示他的负数
正数的补码就是该整数，负数的补码每位求反然后加一
00000001 每位求反 11111110+1=11111111



字符的表示：
1.ASCII
2.汉字编码表示
